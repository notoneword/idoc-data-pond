{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDOC Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "#### - Scrape IDOC page for population report links\n",
    "#### - Download Files\n",
    "[Population Data Sets](https://www2.illinois.gov/idoc/reportsandstatistics/Pages/Prison-Population-Data-Sets.aspx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url = https://www2.illinois.gov/idoc/reportsandstatistics/Pages/Prison-Population-Data-Sets.aspx\n",
      "CWD = D:\\IDOC\\raw\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Files: 38 ['March 2021  Prison Stock.xls', 'Dec 2020  Prison Stock.xls', 'Sept 2020 Prison Pop.xls', 'June 2020 Prison Stock Pop.xls', 'March 2020 Prison Stock.xls', 'Dec 31 2019 Prison Stock pop.xls', 'September 2019 Prison Stock.xls', 'June 2019 Prison Stock.xls', 'March 2019 Prison Stock.xls', 'December 2018_ Prison Stock.xls', 'September 2018 _Prison_Stock.xls', 'June 2018 Prison Internet Data Set.xls', 'March 2018 Prison_Stock_Internet.xls', 'Internet Data Set Prison_Stock_Dec_2017.xls', 'Internet Data Set Prison_Stock_June 2017.xls', 'Internet Data Set Prison_Stock_Dec_2016.xls', 'Prison Population 6-30-16 Data Set.xls', 'Internet Data Set Prison_Stock_Dec_2015.xls', 'June 2015_ Prison_Stock_Internet_Variables.xls', 'Dec 2014_ Prison_Stock_Internet_Variables.xls', 'June 2014_ Prison_Stock_Internet_Variables.xls', 'Dec 2013_Prison_Stock_Internet_Variables.xls', 'June 2013 _ Prison_Stock_Internet_Variables.xls', 'Dec 2012_ Prison_Stock_Internet_Variables.xls', 'June 2012 Prison_Stock_Internet_Variables.xls', 'Dec 2011 Prison Stock Pop.xls', 'June 2011 Prison Stock Pop.xls', 'Dec 2010 Stock Pop.xls', 'June 2010 Stock Pop.xls', 'December 2009 stock pop.xls', 'June 2009 stock pop.xls', 'December 2008 stock pop.xls', 'June 2008 stock pop.xls', 'December 2007 stock pop.xls', 'June 2007 stock pop.xls', 'December 2006 stock pop.xls', 'June 2006 stock pop.xls', 'June 2005 stock pop.xls']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import requests\n",
    "import os\n",
    "\n",
    "base_folder = 'D:\\\\IDOC\\\\'\n",
    "dest_folder = base_folder + 'raw\\\\'\n",
    "processing_folder = base_folder + 'proc\\\\'\n",
    "clean_folder = base_folder + 'clean\\\\'\n",
    "# separate file for all the config values, magic strings?\n",
    "base = 'https://www2.illinois.gov'\n",
    "folder = '/idoc/reportsandstatistics/'\n",
    "docs = 'Documents/'\n",
    "pages = 'Pages/'\n",
    "page = 'Prison-Population-Data-Sets.aspx'\n",
    "url = base + folder + pages + page\n",
    "print('url = '  + url)\n",
    "\n",
    "# processing directories\n",
    "#TODO: S3 buckets\n",
    "if not os.path.exists(dest_folder):\n",
    "    os.mkdir(dest_folder) \n",
    "if not os.path.exists(clean_folder):\n",
    "    os.mkdir(clean_folder)\n",
    "if not os.path.exists(processing_folder):\n",
    "    os.mkdir(processing_folder)\n",
    "    \n",
    "os.chdir(dest_folder)\n",
    "print('CWD = ' + os.getcwd())\n",
    "page_source = urllib.request.urlopen(url).read().decode('utf-8')\n",
    "regex_pattern = '<a href=\"' + folder + docs + '(.*?)\"'\n",
    "\n",
    "files = []\n",
    "\n",
    "doc_links = re.findall(regex_pattern, page_source)\n",
    "for doc_link in doc_links:\n",
    "   #Process the data from the page here.\n",
    "   print('>', end=\"\")\n",
    "   clean_name = urllib.parse.unquote(doc_link)  \n",
    "   files.append(clean_name)\n",
    "   r = requests.get(base + folder + docs + doc_link, allow_redirects=True)\n",
    "   open(clean_name, 'wb').write(r.content)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"Files:\", len(files), files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "##### Rename dataset files based on month/year values\n",
    "##### convert files to CSV, move to processing directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Files in  D:\\IDOC\\raw\\\n",
      ">> Dec 2010 Stock Pop.xls\n",
      ">> Dec 2011 Prison Stock Pop.xls\n",
      ">> Dec 2012_ Prison_Stock_Internet_Variables.xls\n",
      ">> Dec 2013_Prison_Stock_Internet_Variables.xls\n",
      ">> Dec 2014_ Prison_Stock_Internet_Variables.xls\n",
      ">> Dec 2020  Prison Stock.xls\n",
      ">> Dec 31 2019 Prison Stock pop.xls\n",
      ">> December 2006 stock pop.xls\n",
      ">> December 2007 stock pop.xls\n",
      ">> December 2008 stock pop.xls\n",
      ">> December 2009 stock pop.xls\n",
      ">> December 2018_ Prison Stock.xls\n",
      ">> Internet Data Set Prison_Stock_Dec_2015.xls\n",
      ">> Internet Data Set Prison_Stock_Dec_2016.xls\n",
      ">> Internet Data Set Prison_Stock_Dec_2017.xls\n",
      ">> Internet Data Set Prison_Stock_June 2017.xls\n",
      ">> June 2005 stock pop.xls\n",
      ">> June 2006 stock pop.xls\n",
      ">> June 2007 stock pop.xls\n",
      ">> June 2008 stock pop.xls\n",
      ">> June 2009 stock pop.xls\n",
      ">> June 2010 Stock Pop.xls\n",
      ">> June 2011 Prison Stock Pop.xls\n",
      ">> June 2012 Prison_Stock_Internet_Variables.xls\n",
      ">> June 2013 _ Prison_Stock_Internet_Variables.xls\n",
      ">> June 2014_ Prison_Stock_Internet_Variables.xls\n",
      ">> June 2015_ Prison_Stock_Internet_Variables.xls\n",
      ">> June 2018 Prison Internet Data Set.xls\n",
      ">> June 2019 Prison Stock.xls\n",
      ">> June 2020 Prison Stock Pop.xls\n",
      ">> March 2018 Prison_Stock_Internet.xls\n",
      ">> March 2019 Prison Stock.xls\n",
      ">> March 2020 Prison Stock.xls\n",
      ">> March 2021  Prison Stock.xls\n",
      ">> Prison Population 6-30-16 Data Set.xls\n",
      ">> Sept 2020 Prison Pop.xls\n",
      ">> September 2018 _Prison_Stock.xls\n",
      ">> September 2019 Prison Stock.xls\n",
      "\n",
      "New FilesD:\\IDOC\\proc\\:  38 ['200506.csv', '200606.csv', '200612.csv', '200706.csv', '200712.csv', '200806.csv', '200812.csv', '200906.csv', '200912.csv', '201006.csv', '201012.csv', '201106.csv', '201112.csv', '201206.csv', '201212.csv', '201306.csv', '201312.csv', '201406.csv', '201412.csv', '201506.csv', '201512.csv', '201606.csv', '201612.csv', '201706.csv', '201712.csv', '201803.csv', '201806.csv', '201809.csv', '201812.csv', '201903.csv', '201906.csv', '201909.csv', '201912.csv', '202003.csv', '202006.csv', '202009.csv', '202012.csv', '202103.csv']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "  \n",
    "'''  rename file, convert to csv'''\n",
    "def process_file(filename):\n",
    "    new_filename = (processing_folder + normalize_filename(filename) + '.csv')\n",
    "    pd.read_excel(filename).to_csv (new_filename, \n",
    "                  index = None,\n",
    "                  header=True)\n",
    "\n",
    "''' find the month, year values in filename\n",
    "    return in sortable format: monthyear.csv e.g 201012.csv'''\n",
    "def normalize_filename(filename): \n",
    "    new_filename = filename\n",
    "    \n",
    "    month_pattern = '(?:Mar(?:ch)?|Jun(?:e)?|Sept(?:ember)?|Dec(?:ember)?)'\n",
    "    year_pattern = '(?:20[0-1]\\d|2\\d{3})'\n",
    "    # 6-30-16 <-- format needed\n",
    "    alt_date_pattern = '(?:([1-9]|1[012])[- /.](0[1-9]|[12][0-9]|3[01])[- /.](\\d\\d))'\n",
    "    \n",
    "    year = None\n",
    "    try:\n",
    "        month = re.findall(month_pattern, filename)\n",
    "    except Exception as e:        \n",
    "        print(\">>>>>>>>>>>>>>>\", e)        \n",
    "        \n",
    "    if len(month) == 0:        \n",
    "        alt_date = re.findall(alt_date_pattern, filename)\n",
    "        if len(alt_date) > 0: \n",
    "            month = alt_date[0][0]\n",
    "            if len(month) == 1:       \n",
    "                month = \"0\" + month                \n",
    "            year = '20' + alt_date[0][2]\n",
    "    else:         \n",
    "        month = mapMonth(month[0])            \n",
    " \n",
    "    if year is None:\n",
    "        year = re.findall(year_pattern, filename)[0]\n",
    "    \n",
    "    #print(\"Month:\", month,\"Year:\",year)\n",
    "    return (year + month)\n",
    "\n",
    "''' map the various month strings used to appropriate month string'''\n",
    "#TODO: find the module that does this already\n",
    "def mapMonth(month_str):\n",
    "    month_str_to_int_dict = {'March':'03', 'June':'06', 'September':'09', 'Sept':'09', 'Dec':'12', 'December':'12'}\n",
    "    return month_str_to_int_dict[month_str]\n",
    "    \n",
    "    \n",
    "os.chdir(dest_folder)\n",
    "    \n",
    "print('Processing Files in ', dest_folder)\n",
    "for file in os.listdir():\n",
    "    try: \n",
    "        print('>>', file)\n",
    "        process_file(file)\n",
    "    except Exception as e:\n",
    "        print(\">>>>>>>>\", file, e)       \n",
    "\n",
    "print(\"\")\n",
    "        \n",
    "os.chdir(processing_folder)\n",
    "print(\"New Files{}: \".format(processing_folder), len(os.listdir()), os.listdir())\n",
    "os.chdir(base_folder)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from csv import reader\n",
    "\n",
    "def prepare_datafile(filepath):\n",
    "    '''open and read CSV files into Dataset, display header fields'''\n",
    "    try:\n",
    "        file = open(filepath, encoding=\"utf-8\")\n",
    "        dataset = list(reader(file))\n",
    "        # 5 rows before headers\n",
    "        header = dataset[5:6][0]\n",
    "        data = dataset[7:]\n",
    "        #print('Header Fields ({}):\\n{}\\n'.format(len(header),header))\n",
    "        file.close\n",
    "    except FileNotFoundError:\n",
    "        print('***********{} not found.\\n'.format(filepath))\n",
    "        return [],[]\n",
    "    return (header, data)\n",
    "\n",
    "#prepare_datafile('D:\\\\IDOC\\\\clean\\\\12-2010.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explore_data(data, start, end):\n",
    "    '''function for viewing data'''\n",
    "    print('# of rows: {:,}\\n# of columns: {}\\n\\nExamples:'\n",
    "          .format(len(data),len(data[0])))\n",
    "    #List comprehension to print out every row in slice\n",
    "    [print(row) for row in data[start:end]]\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_corrupt_records(data, header_len):\n",
    "    '''find problem row/s (# of fields not equal to header fields) and remove them'''\n",
    "    for row in data:\n",
    "        if len(row) != header_len:\n",
    "            idx = data.index(row)\n",
    "            print('**** Deleting corrupt record at index {}:\\n{}'.format(idx,row))\n",
    "            del data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_duplicates(data, name_idx):\n",
    "    '''find duplicate records'''\n",
    "    unique_rows = []\n",
    "    duplicate_rows = []\n",
    "    for row in data:\n",
    "        name = row[name_idx]\n",
    "        if(name in unique_rows):\n",
    "            duplicate_rows.append(name)\n",
    "        else:\n",
    "            unique_rows.append(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "##### process files by datestring \n",
    "##### keep track of changing header fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Files in D:\\IDOC\\proc\\\n",
      "Processing File 200506.csv\n",
      "Processing File 200606.csv....................\n",
      "Processing File 200612.csv....................\n",
      "Processing File 200706.csv....................\n",
      "Processing File 200712.csv....................\n",
      "Processing File 200806.csv....................\n",
      "Processing File 200812.csv....................\n",
      "Processing File 200906.csv....................\n",
      "Processing File 200912.csv....................\n",
      "Processing File 201006.csv....................\n",
      "Processing File 201012.csv....................\n",
      "Processing File 201106.csv...........\n",
      ">>>>>>>> Header difference found:\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date')\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date2')\n",
      ".\n",
      ">>>>>>>> Header difference found:\n",
      "(11, 'Projected Discharge Date')\n",
      "(11, 'Projected Discharge Date2')\n",
      "........\n",
      "Processing File 201112.csv....................\n",
      "Processing File 201206.csv...........\n",
      ">>>>>>>> Header difference found:\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date2')\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date')\n",
      ".\n",
      ">>>>>>>> Header difference found:\n",
      "(11, 'Projected Discharge Date2')\n",
      "(11, 'Projected Discharge Date')\n",
      "........\n",
      "Processing File 201212.csv............\n",
      ">>>>>>>> Header difference found:\n",
      "(11, 'Projected Discharge  Date2')\n",
      "(11, 'Projected Discharge Date2')\n",
      "........\n",
      "Processing File 201306.csv............\n",
      ">>>>>>>> Header difference found:\n",
      "(11, 'Projected Discharge Date2')\n",
      "(11, 'Projected Discharge  Date2')\n",
      "........\n",
      "Processing File 201312.csv....................\n",
      "Processing File 201406.csv....................\n",
      "Processing File 201412.csv....................\n",
      "Processing File 201506.csv....................\n",
      "Processing File 201512.csv...........\n",
      ">>>>>>>> Header difference found:\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date3')\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date2')\n",
      ".\n",
      ">>>>>>>> Header difference found:\n",
      "(11, 'Projected Discharge Date3')\n",
      "(11, 'Projected Discharge Date2')\n",
      "........\n",
      "Processing File 201606.csv....................\n",
      "Processing File 201612.csv.........\n",
      ">>>>>>>> Header difference found:\n",
      "(8, 'Current Admission Type')\n",
      "(8, 'Admission Type')\n",
      "...........\n",
      "Processing File 201706.csv.........\n",
      ">>>>>>>> Header difference found:\n",
      "(8, 'Admission Type')\n",
      "(8, 'Current Admission Type')\n",
      "...........\n",
      "Processing File 201712.csv....................\n",
      "Processing File 201803.csv....................\n",
      "Processing File 201806.csv....................\n",
      "Processing File 201809.csv....................\n",
      "Processing File 201812.csv........\n",
      ">>>>>>>> Header difference found:\n",
      "(7, 'Current Admission Date3')\n",
      "(7, 'Current Admission Date')\n",
      "...\n",
      ">>>>>>>> Header difference found:\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date4')\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date3')\n",
      ".\n",
      ">>>>>>>> Header difference found:\n",
      "(11, 'Projected Discharge Date4')\n",
      "(11, 'Projected Discharge Date3')\n",
      "........\n",
      "Processing File 201903.csv........\n",
      ">>>>>>>> Header difference found:\n",
      "(7, 'Current Admission Date')\n",
      "(7, 'Current Admission Date3')\n",
      "...\n",
      ">>>>>>>> Header difference found:\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date3')\n",
      "(10, 'Projected Mandatory Supervised Release (MSR) Date4')\n",
      ".\n",
      ">>>>>>>> Header difference found:\n",
      "(11, 'Projected Discharge Date3')\n",
      "(11, 'Projected Discharge Date4')\n",
      "........\n",
      "Processing File 201906.csv....................\n",
      "Processing File 201909.csv....................\n",
      "Processing File 201912.csv....................\n",
      "Processing File 202003.csv....................\n",
      "Processing File 202006.csv....................\n",
      "Processing File 202009.csv....................\n",
      "Processing File 202012.csv....................\n",
      "Processing File 202103.csv....................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "os.chdir(processing_folder)\n",
    "\n",
    "\n",
    "def build_header_dict(headers):\n",
    "    header_values_state = {}\n",
    "    for i in range(0, len(headers)):\n",
    "            header_values_state[i] = headers[i]\n",
    "    #header_values_state = [i:headers[i] for i in range(0, len(headers))]\n",
    "           \n",
    "    return header_values_state\n",
    "    \n",
    "print('Processing Files in', processing_folder)\n",
    "\n",
    "header_fields = {}\n",
    "for file in os.listdir():\n",
    "    try: \n",
    "        print('Processing File', file, end=\"\")\n",
    "        (headers, data) = prepare_datafile(file)\n",
    "        \n",
    "        for x_values, y_values in zip(\n",
    "            build_header_dict(headers).items(), build_header_dict(header_fields).items()):\n",
    "            print(\".\", end=\"\")\n",
    "            if x_values != y_values:\n",
    "                print(\"\")\n",
    "                print('>>>>>>>> Header difference found:\\n{}\\n{}'.format(x_values, y_values))\n",
    "        header_fields = headers\n",
    "        print(\"\")\n",
    "    except Exception as e:\n",
    "        print(\">>>>>>>>\", file, e)       \n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(base_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
